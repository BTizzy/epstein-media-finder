"""
Script 5: Generate Final Report
Creates markdown report with top underreported items
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import json
import yaml
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    """Generate final markdown report"""
    
    # Load config
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # Load results
    json_path = config['output']['results_file']
    with open(json_path, 'r') as f:
        results = json.load(f)
    
    df = pd.DataFrame(results)
    
    # Sort by virality score (ascending - least viral first)
    df = df.sort_values('virality_score')
    
    # Get top 10 underreported
    underreported = df[df['is_underreported'] == True].head(10)
    
    logger.info(f"Generating report for {len(underreported)} items")
    
    # Generate markdown report
    report = f"""# Underreported Epstein Media - Data Set 9

**Analysis Date:** {datetime.now().strftime('%B %d, %Y at %I:%M %p EST')}

---

## Executive Summary

- **Total media files analyzed:** {len(df)}
- **Underreported items found:** {df['is_underreported'].sum()}
- **Top 10 recommendations below**

---

## Methodology

This analysis used FREE web scraping (no paid APIs) to check social media presence:

- **Google Search:** Counted search results for each filename
- **Reddit:** Searched across {', '.join(['r/' + s for s in config['social_platforms']['reddit_subreddits']])}
- **Twitter (via Nitter):** Free Twitter mirror for mention counting

**Virality Score Formula:** (Google results / 100) + (Reddit posts Ã— 3) + (Twitter mentions Ã— 2)

**Underreported Threshold:** Score < 5.0

---

## Top 10 Underreported Media Files

"""
    
    # Add each item
    for rank, (idx, row) in enumerate(underreported.iterrows(), start=1):
        doj_url = f"https://www.justice.gov/epstein/files/DataSet%209/{row['filename']}"
        
        report += f"""
### {rank}. {row['filename']}

- **File ID:** `{row['file_id']}`
- **DOJ URL:** [{row['filename']}]({doj_url})
- **Local Path:** `{row['local_path']}`
- **Thumbnail:** `{row['thumbnail_path']}`

**Social Media Presence:**
- Google Results: {row['google_mentions']}
- Reddit Posts: {row['reddit_mentions']}
- Twitter Mentions: {row['nitter_mentions']}
- **Virality Score: {row['virality_score']}** ðŸ”¥

**Why This is Underreported:**
This file has minimal social media presence compared to other files in the release. It may contain interesting content that hasn't been widely discussed yet.

**Engagement Angle:** [Manual analysis needed - check file content]

---
"""
    
    # Add footer
    report += f"""
## Limitations

1. **Sample Size:** Analyzed first 50 media files from Data Set 9
2. **Social Coverage:** Checked Reddit, Twitter (via Nitter), and Google only
3. **Timing:** Checked within 24 hours of release - some files may gain traction later
4. **Free Tools:** Used web scraping instead of APIs - counts are approximate

## Next Steps

1. **Manual Review:** Open each underreported file to assess content
2. **Verify Engagement:** Confirm files contain newsworthy/interesting content
3. **Social Strategy:** Share most compelling findings on appropriate platforms
4. **Monitor Trends:** Re-check in 48-72 hours to track virality changes

---

*Generated by Epstein Media Finder - Free Version*
*No API costs incurred*
"""
    
    # Save report
    report_path = config['output']['final_report']
    os.makedirs(os.path.dirname(report_path), exist_ok=True)
    
    with open(report_path, 'w') as f:
        f.write(report)
    
    logger.info(f"âœ… Report generated: {report_path}")
    logger.info(f"\n{'='*60}")
    logger.info(f"ðŸŽ‰ ANALYSIS COMPLETE!")
    logger.info(f"ðŸ“„ Read your report: {report_path}")
    logger.info(f"{'='*60}\n")
    
    # Print preview
    print("\n" + "="*60)
    print("REPORT PREVIEW:")
    print("="*60)
    print(report[:1000] + "...")

if __name__ == "__main__":
    main()
